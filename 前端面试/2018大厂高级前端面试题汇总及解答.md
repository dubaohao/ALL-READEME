# 2018 大厂高级前端面试题汇总

面试的公司分别是：

阿里、网易、滴滴、今日头条、有赞、挖财、沪江、饿了么、携程、喜马拉雅、兑吧、微医、寺库、宝宝树、海康威视、蘑菇街、酷家乐、百分点和海风教育

## 阿里

### 使用过的koa2中间件

- koa-router【路由】
- glob【一个规则，允许使用*等符号匹配对应规则的文件】
- koa-view【视图模板渲染】
- koa-bodyparser/koa-body【Request Body的解析器】
- koa-session【HTTP是无状态协议，为了保持用户状态，我们一般使用Session会话，koa-session提供了这样的功能，既支持将会话信息存储在本地Cookie，也支持存储在如Redis, MongoDB这样的外部存储设备。】
- koa-jwt【随着网站前后端分离方案的流行，越来越多的网站从Session Base转为使用Token Base，JWT(Json Web Tokens)作为一个开放的标准被很多网站采用，koa-jwt这个中间件使用JWT认证HTTP请求。】
- koa-helmet【网络安全得到越来越多的重视，[helmet](https://link.jianshu.com?t=https%3A%2F%2Fgithub.com%2Fhelmetjs%2Fhelmet) 通过增加如Strict-Transport-Security, X-Frame-Options, X-Frame-Options等HTTP头提高Express应用程序的安全性，koa-helmet为koa程序提供了类似的功能，参考[Node.js安全清单](https://link.jianshu.com?t=https%3A%2F%2Fsegmentfault.com%2Fa%2F1190000003860400)。】
- koa-cpmpress【当响应体比较大时，我们一般会启用类似Gzip的压缩技术减少传输内容，koa-compress提供了这样的功能，可根据需要进行灵活的配置。】
- koa-logger【koa-logger提供了输出请求日志的功能，包括请求的url、状态码、响应时间、响应体大小等信息，对于调试和跟踪应用程序特别有帮助，[koa-bunyan-logger](https://link.jianshu.com/?t=https%3A%2F%2Fgithub.com%2Fkoajs%2Fbunyan-logger) 提供了更丰富的功能。】
- koa-convert【对于比较老的使用Generate函数的koa中间件(< koa2)，官方提供了一个灵活的工具可以将他们转为基于Promise的中间件供Koa2使用，同样也可以将新的基于Promise的中间件转为旧式的Generate中间件。】
- koa-static【Node.js除了处理动态请求，也可以用作类似Nginx的静态文件服务，在本地开发时特别方便，可用于加载前端文件或后端Fake数据，可结合 [koa-compress](https://link.jianshu.com/?t=https%3A%2F%2Fgithub.com%2Fkoajs%2Fcompress) 和 [koa-mount](https://link.jianshu.com/?t=https%3A%2F%2Fgithub.com%2Fkoajs%2Fmount) 使用。】

### 中间件工作原理

- 初始化koa实例后，我们会用`use`方法来加载中间件(middleware)，会有一个数组来存储中间件，use调用顺序会决定中间件的执行顺序。

- 每个中间件都是一个函数(不是函数将报错)，接收两个参数，**第一个是ctx上下文对象，另一个是next函数(由koa-compose定义)**

  **原理**就是：

  会从middleware数组中取第一个函数开始执行，中间件函数中**调用next方法就会去取下一个中间件函数继续执行**。每个中间件函数执行完毕后都会返回一个**promise对象**。(ps:调用next方法并不是表示当前中间件函数执行完毕了，调用next之后仍可以继续执行其他代码)

  ![洋葱图](F:\Code\github\前端面试\assets\6383319-09c1061cf194e0b8.webp)

### koa-body原理

**首先，介绍前置知识**

HTTP报文主要分为请求报文和响应报文，koa-bodyparser主要针对请求报文的处理。

请求报文主要由以下三个部分组成：

- 报文头部
- 空行
- 报文主体

而koa-bodyparser中的body指的就是请求报文中的报文主体部分。

HTTP底层采用TCP提供可靠的字节流服务，简单而言就是报文主体部分会被转化为二进制数据在网络中传输，所以服务器端首先需要拿到二进制流数据。

谈到网络传输，当然会涉及到传输速度的优化，而其中一种优化方式就是对内容进行压缩编码，常用的压缩编码方式有：

- gzip
- compress
- deflate
- identity（不执行压缩或不会变化的默认编码格式）

服务器端会根据报文头部信息中的Content-Encoding确认采用何种解压编码。

  接下来就需要将二进制数据转换为相应的字符，而字符也有不同的字符编码方式，例如对于中文字符处理差异巨大的UTF-8和GBK，UTF-8编码汉字通常需要三个字节，而GBK只需要两个字节。所以还需要在请求报文的头部信息中设置Content-Type使用的字符编码信息（默认情况下采用的是UTF-8），这样服务器端就可以利用相应的字符规则进行解码，得到正确的字符串。

  拿到字符串之后，服务器端又要问了：客户端，你这一段字符串是啥意思啊？

  根据不同的应用场景，客户端会对字符串采用不同的编码方式，常见的编码方式有：

- URL编码方式: a=1&b=2
- JSON编码方式: {a:1,b:2}

客户端会将采用的字符串编码方式设置在请求报文头部信息的Content-Type属性中，这样服务器端根据相应的字符串编码规则进行解码，就能够明白客户端所传递的信息了。

**重点**

- 获取二进制数据流

> Node.js 获取报文主体二进制数据，主要通过监听request对象的data。【而koa-bodyparser主要是对[co-body](https://github.com/cojs/co-body)的封装，而【co-body】中主要是采用[raw-body](https://github.com/stream-utils/raw-body)模块获取请求报文主体的二进制数据流，【row-body】主要是对上述示例代码的封装和健壮性处理。】

- 内容解码

> 客户端会将内容编码的方式放入请求报文头部信息Content-Encoding属性中，服务器端接收报文主体的二进制数据了时，会根据该头部信息进行解压操作，当然服务器端可以在响应报文头部信息Accept-Encoding属性中添加支持的解压方式。
>
> 而【row-body】主要采用inflation模块进行解压处理。

- 字符解码

> 一般而言，UTF-8是互联网中主流的字符编码方式，前面也提到了还有GBK编码方式，相比较UTF-8，它编码中文只需要2个字节，那么在字符解码时误用UTF-8解码GBK编码的字符，就会出现中文乱码的问题。
>
> NodeJS主要通过Buffer处理二进制数据流，但是它并不支持GBK字符编码方式，需要通过iconv-lite模块进行处理。

- 字符串解码

> 前面已经提到了字符串的二种编码方式，它们对应的Content-Type分别为：
>
> 1. URL编码 application/x-www-form-urlencoded
> 2. JSON编码 application/json
>
> 对于前端来说，URL编码并不陌生，经常会用于URL拼接操作，唯一需要注意的是不要忘记对键值对进行decodeURIComponent()处理。
>
> 当客户端发送请求主体时，需要进行编码操作：
>
> > 'a=1&b=2&c=3'
>
> 服务器端再根据URL编码规则解码，得到相应的对象。
>
> ```
> // URL编码方式 简单的解码方法实现
> function decode (qs, sep = '&', eq = '=') {
>   const obj = {}
>   qs = qs.split(sep)
> 
>   for (let i = 0, max = qs.length; i < max; i++) {
>     const item = qs[i]
>     const index = item.indexOf(eq)
> 
> let key, value
> 
> if (~index) {
>   key = item.substr(0, index)
>   value = item.substr(index + 1)
> } else {
>   key = item
>   value = ''
> }
> 
> key = decodeURIComponent(key)
> value = decodeURIComponent(value)
> 
> if (!obj.hasOwnProperty(key)) {
>   obj[key] = value
> }
> 
>   }
>   return obj
> }
> 
> console.log(decode('a=1&b=2&c=3')) // { a: '1', b: '2', c: '3' }
> ```
>
> URL编码方式适合处理简单的键值对数据，并且很多框架的Ajax中的Content-Type默认值都是它，但是对于复杂的嵌套对象就不太好处理了，这时就需要JSON编码方式大显身手了。
>
> 客户端发送请求主体时，只需要采用JSON.stringify进行编码。服务器端只需要采用JSON.parse进行解码即可：
>
> ```
> const strictJSONReg = /^[\x20\x09\x0a\x0d]*(\[|\{)/;
> function parse(str) {
>   if (!strict) return str ? JSON.parse(str) : str;
>   // 严格模式下，总是返回一个对象
>   if (!str) return {};
>   // 是否为合法的JSON字符串
>   if (!strictJSONReg.test(str)) {
>     throw new Error('invalid JSON, only supports object and array');
>   }
>   return JSON.parse(str);
> 
> }
> ```
>
> 除了上述两种字符串编码方式，koa-bodyparser还支持不采用任何字符串编码方式的普通字符串。
>
> 三种字符串编码的处理方式由【co-body】模块提供，koa-bodyparser中通过判断当前Content-Type类型，调用不同的处理方式，将获取到的结果挂载在ctx.request.body：
>
> ```
>  return async function bodyParser(ctx, next) {
>     if (ctx.request.body !== undefined) return await next();
>     if (ctx.disableBodyParser) return await next();
>     try {
>       // 最重要的一步 将解析的内容挂载到koa的上下文中
>       const res = await parseBody(ctx);
>       ctx.request.body = 'parsed' in res ? res.parsed : {};
>       if (ctx.request.rawBody === undefined) ctx.request.rawBody = res.raw; // 保存原始字符串
>     } catch (err) {
>       if (onerror) {
>         onerror(err, ctx);
>       } else {
>         throw err;
>       }
>     }
>     await next();
>   };
> 
>   async function parseBody(ctx) {
>     if (enableJson && ((detectJSON && detectJSON(ctx)) || ctx.request.is(jsonTypes))) {
>       return await parse.json(ctx, jsonOpts); // application/json等json type
>     }
>     if (enableForm && ctx.request.is(formTypes)) {
>       return await parse.form(ctx, formOpts); // application/x-www-form-urlencoded
>     }
>     if (enableText && ctx.request.is(textTypes)) {
>       return await parse.text(ctx, textOpts) || ''; // text/plain
>     }
>     return {};
>   }
> 
> };
> ```
>
> 其实还有一种比较常见的Content-type，当采用表单上传时，报文主体中会包含多个实体主体：
>
> ```
> ------WebKitFormBoundaryqsAGMB6Us6F7s3SF
> Content-Disposition: form-data; name="image"; filename="image.png"
> Content-Type: image/png
> 
> ------WebKitFormBoundaryqsAGMB6Us6F7s3SF
> Content-Disposition: form-data; name="text"
> 
> ------WebKitFormBoundaryqsAGMB6Us6F7s3SF--
> ```
>
> 这种方式处理相对比较复杂，koa-bodyparser中并没有提供该Content-Type的解析。

![图解http](F:\Code\github\前端面试\assets\16851d10d3942128)



### 介绍自己写过的中间件

??????

### 有没有涉及到Cluster

HTTP服务器用于响应来自客户端的请求，当客户端请求数逐渐增大时服务端的处理机制有多种，如tomcat的多线程、nginx的事件循环等。而对于node而言，由于其也采用事件循环和异步I/O机制，因此在高I/O并发的场景下性能非常好，但是由于单个node程序仅仅利用单核cpu，因此为了更好利用系统资源就需要fork多个node进程执行HTTP服务器逻辑，所以node内建模块提供了**child_process和cluster**模块。

利用child_process模块，我们可以执行shell命令，可以fork子进程执行代码，也可以直接执行二进制文件；利用cluster模块，使用node封装好的API、IPC通道和调度机可以非常简单的创建包括`一个master进程下HTTP代理服务器 + 多个worker进程多个HTTP应用服务器`的架构，并提供两种调度子进程算法。

本文主要针对cluster模块讲述node是如何实现简介高效的服务集群创建和调度的。那么就从代码进入本文的主题：

**code1**

```
const cluster = require('cluster');
const http = require('http');

if (cluster.isMaster) {
  let numReqs = 0;
  setInterval(() => {
    console.log(`numReqs = ${numReqs}`);
  }, 1000);

  function messageHandler(msg) {
    if (msg.cmd && msg.cmd === 'notifyRequest') {
      numReqs += 1;
    }
  }
  const numCPUs = require('os').cpus().length;
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  for (const id in cluster.workers) {
    cluster.workers[id].on('message', messageHandler);
  }

} else {

  // Worker processes have a http server.
  http.Server((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');
    process.send({ cmd: 'notifyRequest' });
  }).listen(8000);
}
```

主进程创建多个子进程

主进程创建多个子进程，同时接受子进程传来的消息，循环输出处理请求的数量；

子进程创建http服务器，侦听8000端口并返回响应。

泛泛的大道理谁都了解，可是这套代码如何运行在主进程和子进程中呢？父进程如何向子进程传递客户端的请求？多个子进程共同侦听8000端口，会不会造成端口reuse error？每个服务器进程最大可有效支持多少并发量？主进程下的代理服务器如何调度请求？ 这些问题，如果不深入进去便永远只停留在写应用代码的层面，而且不了解cluster集群创建的多进程与使用child_process创建的进程集群的区别，也写不出符合业务的最优代码，因此，深入cluster还是有必要的。

#### cluster与net

cluster模块与net模块息息相关，而net模块又和底层socket有联系，至于socket则涉及到了系统内核，这样便由表及里的了解了node对底层的一些优化配置，这是我们的思路。介绍前，笔者仔细研读了node的js层模块实现，在基于自身理解的基础上诠释上节代码的实现流程，力图做到清晰、易懂，如果有某些纰漏也欢迎读者指出，只有在互相交流中才能收获更多。

**一套代码，多次执行**

很多人对**code1**代码如何在主进程和子进程执行感到疑惑，怎样通过*cluster.isMaster*判断语句内的代码是在主进程执行，而其他代码在子进程执行呢？

其实只要你深入到了node源码层面，这个问题很容易作答。cluster模块的代码只有一句：

```
module.exports = ('NODE_UNIQUE_ID' in process.env) ?
                require('internal/cluster/child') :
                require('internal/cluster/master');
```

只需要判断当前进程有没有环境变量“NODE_UNIQUE_ID”就可知道当前进程是否是主进程；而变量“NODE_UNIQUE_ID”则是在主进程fork子进程时传递进去的参数，因此采用cluster.fork创建的子进程是一定包含“NODE_UNIQUE_ID”的。

**这里需要指出的是，必须通过cluster.fork创建的子进程才有NODE_UNIQUE_ID变量，如果通过child_process.fork的子进程，在不传递环境变量的情况下是没有NODE_UNIQUE_ID的。因此，当你在child_process.fork的子进程中执行cluster.isMaster判断时，返回 true。**

**主进程和服务器**

**code1**中，并没有在cluster.isMaster的条件语句中创建服务器，也没有提供服务器相关的路径、端口和fd，那么主进程中是否存在TCP服务器，有的话到底是什么时候怎么创建的？

相信大家在学习nodejs时阅读的各种书籍都介绍过在集群模式下，主进程的服务器会接受到请求然后发送给子进程，那么问题就来到主进程的服务器到底是如何创建呢？主进程服务器的创建离不开与子进程的交互，毕竟与创建服务器相关的信息全在子进程的代码中。

当子进程执行时，http模块会调用net模块(确切的说，http.Server继承net.Server)，创建net.Server对象，同时侦听端口。创建net.Server实例，调用构造函数返回。创建的net.Server实例调用listen(8000)，等待accpet连接。那么，子进程如何传递服务器相关信息给主进程呢？答案就在listen函数中。我保证，net.Server.prototype.listen函数绝没有表面上看起来的那么简单，它涉及到了许多IPC通信和兼容性处理，可以说HTTP服务器创建的所有逻辑都在listen函数中。

```
http.Server((req, res) => {
    res.writeHead(200);
    res.end('hello world\n');
    process.send({ cmd: 'notifyRequest' });
  }).listen(8000);
```

> 延伸下，在学习linux下的socket编程时，服务端的逻辑依次是执行`socket(),bind(),listen()和accept()`，在接收到客户端连接时执行`read(),write()`调用完成TCP层的通信。那么，对应到node的net模块好像只有**listen()**阶段，这是不是很难对应socket的四个阶段呢？其实不然，node的net模块把“bind，listen”操作全部写入了net.Server.prototype.listen中，清晰的对应底层socket和TCP三次握手，而向上层使用者只暴露简单的listen接口。

**code2**

```
Server.prototype.listen = function() {

  ...

  // 根据参数创建 handle句柄
  options = options._handle || options.handle || options;
  // (handle[, backlog][, cb]) where handle is an object with a handle
  if (options instanceof TCP) {
    this._handle = options;
    this[async_id_symbol] = this._handle.getAsyncId();
    listenInCluster(this, null, -1, -1, backlogFromArgs);
    return this;
  }
  ...
  var backlog;
  if (typeof options.port === 'number' || typeof options.port === 'string') {
    if (!isLegalPort(options.port)) {
      throw new RangeError('"port" argument must be >= 0 and < 65536');
    }
    backlog = options.backlog || backlogFromArgs;
    // start TCP server listening on host:port
    if (options.host) {
      lookupAndListen(this, options.port | 0, options.host, backlog,
              options.exclusive);

    } else { // Undefined host, listens on unspecified address
      // Default addressType 4 will be used to search for master server
      listenInCluster(this, null, options.port | 0, 4,
                      backlog, undefined, options.exclusive);
    }
    return this;
  }
  ...
  throw new Error('Invalid listen argument: ' + util.inspect(options));
};
```

由于本文只探究cluster模式下HTTP服务器的相关内容，因此我们只关注有关TCP服务器部分，其他的Pipe（domain socket）服务不考虑。

listen函数可以侦听端口、路径和指定的fd，因此在listen函数的实现中判断各种参数的情况，我们最为关心的就是侦听端口的情况，在成功进入条件语句后发现所有的情况最后都执行了listenInCluster函数而返回，因此有必要继续探究。

**code3**

```
function listenInCluster(server, address, port, addressType,
                         backlog, fd, exclusive) {.
  if (cluster.isMaster || exclusive) {
    server._listen2(address, port, addressType, backlog, fd);
    return;
  }
  // 后续代码为worker执行逻辑
  const serverQuery = {
    address: address,
    port: port,
    addressType: addressType,
    fd: fd,
    flags: 0
  };
  ... 
  cluster._getServer(server, serverQuery, listenOnMasterHandle);
}
```

listenInCluster函数传入了各种参数，如server实例、ip、port、ip类型（IPv6和IPv4）、backlog（底层服务端socket处理请求的最大队列）、fd等，它们不是必须传入，比如创建一个TCP服务器，就仅仅需要一个port即可。

简化后的listenInCluster函数很简单，cluster模块判断当前进程为主进程时，执行_listen2函数；否则，在子进程中执行cluster._getServer函数，同时像函数传递serverQuery对象，即创建服务器需要的相关信息。

因此，我们可以大胆假设，子进程在cluster._getServer函数中向主进程发送了创建服务器所需要的数据，即serverQuery。实际上也确实如此：

**code4**

```
cluster._getServer = function(obj, options, cb) {
  const message = util._extend({
    act: 'queryServer',
    index: indexes[indexesKey],
    data: null
  }, options);
  send(message, function modifyHandle(reply, handle) => {
    if (typeof obj._setServerData === 'function')
      obj._setServerData(reply.data);
    if (handle)
      shared(reply, handle, indexesKey, cb);  // Shared listen socket.
    else
      rr(reply, indexesKey, cb);              // Round-robin.
  });
};
```

子进程在该函数中向已建立的IPC通道发送内部消息message，该消息包含之前提到的serverQuery信息，同时包含**act: 'queryServer'**字段，等待服务端响应后继续执行回调函数modifyHandle。

主进程接收到子进程发送的内部消息，会根据**act: 'queryServer'**执行对应queryServer方法，完成服务器的创建，同时发送回复消息给子进程，子进程执行回调函数modifyHandle，继续接下来的操作。

至此，针对主进程在cluster模式下如何创建服务器的流程已完全走通，主要的逻辑是在子进程服务器的listen过程中实现。

**net模块与socket**

上节提到了node中创建服务器无法与socket创建对应的问题，本节就该问题做进一步解释。在net.Server.prototype.listen函数中调用了listenInCluster函数，listenInCluster会在主进程或者子进程的回调函数中调用_listen2函数，对应底层服务端socket建立阶段的正是在这里。

```
function setupListenHandle(address, port, addressType, backlog, fd) {
  // worker进程中，_handle为fake对象，无需创建
  if (this._handle) {
    debug('setupListenHandle: have a handle already');
  } else {
    debug('setupListenHandle: create a handle');
    if (rval === null)
      rval = createServerHandle(address, port, addressType, fd);
    this._handle = rval;
  }
  this[async_id_symbol] = getNewAsyncId(this._handle);
  this._handle.onconnection = onconnection;
  var err = this._handle.listen(backlog || 511);
}
```

通过createServerHandle函数创建句柄（句柄可理解为用户空间的socket），同时给属性onconnection赋值，最后侦听端口，设定backlog。

那么，socket处理请求过程“socket(),bind()”步骤就是在createServerHandle完成。

```
function createServerHandle(address, port, addressType, fd) {
  var handle;
  // 针对网络连接，绑定地址
  if (address || port || isTCP) {
    if (!address) {
      err = handle.bind6('::', port);
      if (err) {
        handle.close();
        return createServerHandle('0.0.0.0', port);
      }
    } else if (addressType === 6) {
      err = handle.bind6(address, port);
    } else {
      err = handle.bind(address, port);
    }
  }
  return handle;
}
```

在createServerHandle中，我们看到了如何创建socket（createServerHandle在底层利用node自己封装的类库创建TCP handle），也看到了bind绑定ip和地址，那么node的net模块如何接收客户端请求呢？

必须深入c++模块才能了解node是如何实现在c++层面调用js层设置的onconnection回调属性，v8引擎提供了c++和js层的类型转换和接口透出，在c++的tcp_wrap中：

```
void TCPWrap::Listen(const FunctionCallbackInfo<Value>& args) {
  TCPWrap* wrap;
  ASSIGN_OR_RETURN_UNWRAP(&wrap,
                          args.Holder(),
                          args.GetReturnValue().Set(UV_EBADF));
  int backloxxg = args[0]->Int32Value();
  int err = uv_listen(reinterpret_cast<uv_stream_t*>(&wrap->handle_),
                      backlog,
                      OnConnection);
  args.GetReturnValue().Set(err);
}
```

我们关注uv_listen函数，它是libuv封装后的函数，传入了**handle_,backlog和OnConnection回调函数**，其中handle_为node调用libuv接口创建的socket封装，OnConnection函数为socket接收客户端连接时执行的操作。我们可能会猜测在js层设置的onconnction函数最终会在OnConnection中调用，于是进一步深入探查node的connection_wrap c++模块：

```
template <typename WrapType, typename UVType>
void ConnectionWrap<WrapType, UVType>::OnConnection(uv_stream_t* handle,int status) {
  if (status == 0) {
    if (uv_accept(handle, client_handle))
      return;
    // Successful accept. Call the onconnection callback in JavaScript land.
    argv[1] = client_obj;
  }
  wrap_data->MakeCallback(env->onconnection_string(), arraysize(argv), argv);
}
```

过滤掉多余信息便于分析。当新的客户端连接到来时，libuv调用OnConnection，在该函数内执行uv_accept接收连接，最后将js层的回调函数onconnection[通过env->onconnection_string()获取js的回调]和接收到的客户端socket封装传入MakeCallback中。其中，argv数组的第一项为错误信息，第二项为已连接的clientSocket封装，最后在MakeCallback中执行js层的onconnection函数，该函数的参数正是argv数组传入的数据，“错误代码和clientSocket封装”。

**js层的onconnection回调**

```
function onconnection(err, clientHandle) {
  var handle = this;
  if (err) {
    self.emit('error', errnoException(err, 'accept'));
    return;
  }
  var socket = new Socket({
    handle: clientHandle,
    allowHalfOpen: self.allowHalfOpen,
    pauseOnCreate: self.pauseOnConnect
  });
  socket.readable = socket.writable = true;
  self.emit('connection', socket);
}
```

这样，node在C++层调用js层的onconnection函数，构建node层的socket对象，并触发connection事件，完成底层socket与node net模块的连接与请求打通。

至此，我们打通了socket连接建立过程与net模块（js层）的流程的交互，这种封装让开发者在不需要查阅底层接口和数据结构的情况下，仅使用node提供的http模块就可以快速开发一个应用服务器，将目光聚集在业务逻辑中。

> backlog是已连接但未进行accept处理的socket队列大小。在linux 2.2以前，backlog大小包括了半连接状态和全连接状态两种队列大小。linux 2.2以后，分离为两个backlog来分别限制半连接SYN_RCVD状态的未完成连接队列大小跟全连接ESTABLISHED状态的已完成连接队列大小。这里的半连接状态，即在三次握手中，服务端接收到客户端SYN报文后并发送SYN+ACK报文后的状态，此时服务端等待客户端的ACK，全连接状态即服务端和客户端完成三次握手后的状态。backlog并非越大越好，当等待accept队列过长，服务端无法及时处理排队的socket，会造成客户端或者前端服务器如nignx的连接超时错误，出现**“error: Broken Pipe”**。因此，node默认在socket层设置backlog默认值为511，这是因为nginx和redis默认设置的backlog值也为此，尽量避免上述错误。

**多个子进程与端口复用**

再回到关于cluster模块的主线中来。code1中，主进程与所有子进程通过消息构建出侦听8000端口的TCP服务器，那么子进程中有没有也创建一个服务器，同时侦听8000端口呢？其实，在子进程中压根就没有这回事，如何理解呢？子进程中确实创建了net.Server对象，可是它没有像主进程那样在libuv层构建socket句柄，子进程的net.Server对象使用的是一个人为fake出的一个假句柄来“欺骗”使用者端口已侦听，这样做的目的是为了集群的负载均衡，这又涉及到了cluster模块的均衡策略的话题上。

在本节有关cluster集群端口侦听以及请求处理的描述，都是基于cluster模式的默认策略RoundRobin之上讨论的，关于调度策略的讨论，我们放在下节进行。

在**主进程与服务器**这一章节最后，我们只了解到主进程是如何创建侦听给定端口的TCP服务器的，此时子进程还在等待主进程创建后发送的消息。当主进程发送创建服务器成功的消息后，子进程会执行modifyHandle回调函数。还记得这个函数吗？**主进程与服务器**这一章节最后已经贴出来它的源码：

```
function modifyHandle(reply, handle) => {
    if (typeof obj._setServerData === 'function')
      obj._setServerData(reply.data);
    if (handle)
      shared(reply, handle, indexesKey, cb);  // Shared listen socket.
    else
      rr(reply, indexesKey, cb);              // Round-robin.
  }
```

它会根据主进程是否返回handle句柄（即libuv对socket的封装）来选择执行函数。由于cluter默认采用RoundRobin调度策略，因此主进程返回的handle为null，执行函数rr。在该函数中，做了上文提到的hack操作，作者fake了一个假的handle对象，“欺骗”上层调用者：

```
function listen(backlog) {
    return 0;
  }
  const handle = { close, listen, ref: noop, unref: noop };
  handles[key] = handle;
  cb(0, handle);
```

看到了吗？fake出的handle.listen并没有调用libuv层的Listen方法，它直接返回了。这意味着什么？？子进程压根没有创建底层的服务端socket做侦听，所以在子进程创建的HTTP服务器侦听的端口根本不会出现端口复用的情况。 最后，调用cb函数，将fake后的handle传递给上层net.Server，设置net.Server对底层的socket的引用。此后，子进程利用fake后的handle做端口侦听（其实压根啥都没有做），执行成功后返回。

那么子进程TCP服务器没有创建底层socket，如何接受请求和发送响应呢？这就要依赖IPC通道了。既然主进程负责接受客户端请求，那么理所应当由主进程分发客户端请求给某个子进程，由子进程处理请求。实际上也确实是这样做的，主进程的服务器中会创建RoundRobinHandle决定分发请求给哪一个子进程，筛选出子进程后发送newconn消息给对应子进程：

```
  const message = { act: 'newconn', key: this.key };
  sendHelper(worker.process, message, handle, (reply) => {
    if (reply.accepted)
      handle.close();
    else
      this.distribute(0, handle);  // Worker is shutting down. Send to another.
    this.handoff(worker);
  });
```

子进程接收到newconn消息后，会调用内部的onconnection函数，先向主进程发送开始处理请求的消息，然后执行业务处理函数handle.onconnection。还记得这个handle.onconnection吗？它正是上节提到的node在c++层执行的js层回调函数，在handle.onconnection中构造了net.Socket对象标识已连接的socket，最后触发connection事件调用开发者的业务处理函数（此时的数据处理对应在网络模型的第四层传输层中，node的http模块会从socket中获取数据做应用层的封装，解析出请求头、请求体并构造响应体），这样便从内核socket->libuv->js依次执行到开发者的业务逻辑中。

到此为止，相信读者已经明白node是如何处理客户端的请求了，那么下一步继续探究node是如何分发客户端的请求给子进程的。

### 请求分发策略

上节提到cluster模块默认采用RoundRobin调度策略，那么还有其他策略可以选择吗？答案是肯定的，在windows机器中，cluster模块采用的是共享服务端socket方式，通俗点说就是由操作系统进行调度客户端的请求，而不是由node程序调度。其实在node v0.8以前，默认的集群模式就是采用操作系统调度方式进行，直到cluster模块的加入才有了改变。

那么，RoundRobin调度策略到底是怎样的呢？

```
RoundRobinHandle.prototype.distribute = function(err, handle) {
  this.handles.push(handle);
  const worker = this.free.shift();
  if (worker)
    this.handoff(worker);
};

// 发送消息和handle给对应worker进程，处理业务逻辑
RoundRobinHandle.prototype.handoff = function(worker) {
  if (worker.id in this.all === false) {
    return;  // Worker is closing (or has closed) the server.
  }
  const handle = this.handles.shift();
  if (handle === undefined) {
    this.free.push(worker);  // Add to ready queue again.
    return;
  }
  const message = { act: 'newconn', key: this.key };
  sendHelper(worker.process, message, handle, (reply) => {
    if (reply.accepted)
      handle.close();
    else
      this.distribute(0, handle);  // Worker is shutting down. Send to another.
    this.handoff(worker);
  });
};
```

核心代码就是这两个函数，浓缩的是精华。`distribute函数负责筛选出处理请求的子进程，this.free数组存储空闲的子进程，this.handles数组存放待处理的用户请求。handoff函数获取排队中的客户端请求，并通过IPC发送句柄handle和newconn消息，等待子进程返回。当子进程返回正在处理请求消息时，在此执行handoff函数，继续分配请求给该子进程，不管该子进程上次请求是否处理完成（node的异步特性和事件循环可以让单进程处理多请求）。`按照这样的策略，主进程每fork一个子进程，都会调用handoff函数，进入该子进程的处理循环中。一旦主进程没有缓存的客户端请求时（this.handles为空），便会将当前子进程加入free空闲队列，等待主进程的下一步调度。这就是cluster模式的RoundRobin调度策略，每个子进程的处理逻辑都是一个闭环，直到主进程缓存的客户端请求处理完毕时，该子进程的处理闭环才被打开。

这么简单的实现带来的效果却是不小，经过全世界这么多使用者的尝试，主进程分发请求还是很平均的，如果RoundRobin的调度需求不满足你业务中的要求，你可以尝试仿照RoundRobin模块写一个另类的调度算法。

那么cluster模块在windows系统中采用的shared socket策略（后文简称SS策略）是什么呢？采用SS策略调度算法，子进程的服务器工作逻辑完全不同于上文中所讲的那样，子进程创建的TCP服务器会在底层侦听端口并处理响应，这是如何实现的呢？SS策略的核心在于IPC传输句柄的文件描述符，并且在C++层设置端口的**SO_REUSEADDR**选项，最后根据传输的文件描述符还原出handle(net.TCP)，处理请求。这正是shared socket名称由来，共享文件描述符。

**子进程继承父进程fd，处理请求**

```
import socket
import os
def main():
    serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    serversocket.bind(("127.0.0.1", 8888))
    serversocket.listen(0)
    # Child Process
    if os.fork() == 0:
        accept_conn("child", serversocket)
    accept_conn("parent", serversocket)
def accept_conn(message, s):
    while True:
        c, addr = s.accept()
        print 'Got connection from in %s' % message
        c.send('Thank you for your connecting to %s\n' % message)
        c.close()
if __name__ == "__main__":
    main()
```

> 需要指出的是，在子进程中根据文件描述符还原出的handle，不能再进行bind(ip,port)和listen(backlog)操作，只有主进程创建的handle可以调用这些函数。子进程中只能选择accept、read和write操作。

既然SS策略传递的是master进程的服务端socket的文件描述符，子进程侦听该描述符，那么由谁来调度哪个子进程处理请求呢？这就是由操作系统内核来进行调度。可是内核调度往往出现[意想不到](https://www.baidu.com/s?wd=%E6%84%8F%E6%83%B3%E4%B8%8D%E5%88%B0&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)的效果，在linux下导致请求往往集中在某几个子进程中处理。这从内核的调度策略也可以推算一二，内核的进程调度离不开**上下文切换**，上下文切换的代价很高，不仅需要保存当前进程的**代码、数据和堆栈等用户空间数据，还需要保存各种寄存器，如PC，ESP**，最后还需要恢复被调度进程的上下文状态，仍然包括**代码、数据和各种寄存器**，因此代价非常大。而linux内核在调度这些子进程时往往倾向于唤醒最近被阻塞的子进程，上下文切换的代价相对较小。而且内核的调度策略往往受到当前系统的运行任务数量和资源使用情况，对专注于业务开发的http服务器影响较大，因此会造成某些子进程的负载严重不均衡的状况。那么为什么cluster模块默认会在windows机器中采用SS策略调度子进程呢？原因是node在windows平台采用的IOCP来最大化性能，它使得传递连接的句柄到其他进程的成本很高，因此采用默认的依靠操作系统调度的SS策略。

SS调度策略非常简单，主进程直接通过IPC通道发送handle给子进程即可，此处就不针对代码进行分析了。此处，笔者利用node的child_process模块实现了一个简易的SS调度策略的服务集群，读者可以更好的理解：

**master代码**

```
var net = require('net');
var cp = require('child_process');
var w1 = cp.fork('./singletest/worker.js');
var w2 = cp.fork('./singletest/worker.js');
var w3 = cp.fork('./singletest/worker.js');
var w4 = cp.fork('./singletest/worker.js');
var server = net.createServer();
server.listen(8000,function(){
  // 传递句柄
  w1.send({type: 'handle'},server);
  w2.send({type: 'handle'},server);
  w3.send({type: 'handle'},server);
  w4.send({type: 'handle'},server);
  server.close();
});
```

**child代码**

```
var server = require('http').createServer(function(req,res){
  res.write(cluster.isMaster + '');
  res.end(process.pid+'')
})
var cluster = require('cluster');
process.on('message',(data,handle)=>{
  if(data.type !== 'handle')
    return;
  handle.on('connection',function(socket){
    server.emit('connection',socket)
  });
});
```

这种方式便是SS策略的典型实现，不推荐使用者尝试。

#### 结尾

开篇提到的一些问题至此都已经解答完毕，关于cluster模块的一些具体实现本文不做详细描述，有兴趣感受node源码的同学可以在阅读本文的基础上再翻阅，这样[事半功倍](https://www.baidu.com/s?wd=%E4%BA%8B%E5%8D%8A%E5%8A%9F%E5%80%8D&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)。本文是在node源码和笔者的计算机网络基础之上混合后的产物，起因于笔者研究PM2的cluster模式下God进程的具体实现。在尝试几天仔细研读node cluster相关模块后有感于其良好的封装性，故产生将其内部实现原理和技巧向日常开发者所展示的想法，最后有了这篇文章。

那么，阅读了这篇文章，熟悉了cluster模式的具体实现原理，对于日常开发者有什么促进作用呢？首先，能不停留在**使用**层面，深入到具体实现原理中去，这便是比大多数人强了；在理解实现机制的阶段下，如果能反哺业务开发就更有意义了。比如，根据业务设计出更匹配的负载均衡逻辑；根据服务的日常QPS设置合理的backlog值等；最后，在探究实现的过程中，我们又回顾了许多离应用层开发人员难以接触到的底层网络编程和操作系统知识，这同时也是学习深入的过程。

接下来，笔者可能会抽时间针对node的其他常用模块做一次细致的解读。其实，node较为重要的**Stream**模块笔者已经分析过了，node中的Stream、深入node之Transform，经过深入探究之后在日常开发node应用中有着很大的提升作用，读者们可以尝试下。既然提到了Stream模块，那么结合本文的net模块解析，我们就非常容易理解node http模块的实现了，因为http模块正是基于**net和Stream**模块实现的。那么下一篇文章就针对http模块做深入解析吧！

### 介绍pm2

node.js部署PM2

如果直接通过node app来启动，如果报错了可能直接停在整个运行，supervisor感觉只是拿来用作开发环境的。再网上找到pm2.目前似乎最常见的线上部署nodejs项目的有forever,pm2这两种。
使用场合:
- supervisor是开发环境用。
- forever管理多个站点，每个站点访问量不大，不需要监控。
- nodemon 是开发环境使用，修改自动重启。
- pm2 网站访问量比较大,需要完整的监控界面。

#### PM2的主要特性:

- 内建负载均衡（使用Node cluster 集群模块）
- 后台运行
- 0秒停机重载，我理解大概意思是维护升级的时候不需要停机.
- 具有Ubuntu和CentOS 的启动脚本
- 停止不稳定的进程（避免无限循环）
- 控制台检测
- 提供 HTTP API
- 远程控制和实时的接口API ( Nodejs 模块,允许和PM2进程管理器交互 )
　　**1、最常用的属nohup了，其实就是在后台执行进程，末尾加个&**

```
[zhoujie@ops-dev ~]$ nohup node /home/zhoujie/ops/app.js &
[1] 31490nohup: ignoring input and appending output to `nohup.out'
```
即此时程序已启动，直接访问即可，原程序的的标准输出被自动改向到当前目录下的nohup.out文件，起到了log的作用。该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup就是不挂起的意思( no hang up)。

该命令的一般形式为：**nohup command &**这个不太靠谱的样子，经常默默的进程在后台就挂了

 **2、用screen另开一个屏幕，这种方式可以直接在屏幕上看到程序运行情况**

给该应用程序开个screen，如：screen -r ops ，用npm start启动，
退出该后台：ctrl + a，再按d，可不能直接ctrl +c，否则就退出了
这种方式很不专业，呵呵，不过方便看在生产环境的操作。
这个本质上用的forever，package.json里配置的：

```
  "scripts": {
    "start": "forever app.js",
    "test": "supervisor app.js"
  },
```
　　**3、PM2**
使用它要先安装它，用root账号和全局模式安装一下：
```
npm install -g pm2
```
用它来启动程序（在当前目录下可以直接启动，**pm2 start app.js** --name uops）
[![复制代码](F:\Code\github\前端面试\assets\copycode.gif)](javascript:void(0);)

```
[zhoujie@ops-dev uops]$ pm2 start app.js 
[PM2] Spawning PM2 daemon
[PM2] Success
[PM2] Process app.js launched
┌──────────┬────┬──────┬─────┬────────┬───────────┬────────┬─────────────┬──────────┐
│ App name │ id │ mode │ PID │ status │ restarted │ uptime │      memory │ watching │
├──────────┼────┼──────┼─────┼────────┼───────────┼────────┼─────────────┼──────────┤
│ app      │ 0  │ fork │ 308 │ online │         0 │ 0s     │ 21.879 MB   │ disabled │
└──────────┴────┴──────┴─────┴────────┴───────────┴────────┴─────────────┴──────────┘
 Use `pm2 info <id|name>` to get more details about an app
[zhoujie@ops-dev uops]$
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

看，它显示了Success，程序已经默默的成功的启动了，可以实时监控程序的运行，比如执行个**pm2 restart**，则上述restarted那栏变成1，可以显示程序运行了多长时间、占用内存大小，实在是太赞啦！

![img](F:\Code\github\前端面试\assets\071738232036886.jpg)

终止程序也很简单：**pm2 stop** 

![img](F:\Code\github\前端面试\assets\071742299685132.jpg)

列举出所有用pm2启动的程序：**pm2 list**

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[zhoujie@ops-dev uops]$ pm2 list
┌──────────┬────┬──────┬─────┬────────┬───────────┬────────┬─────────────┬──────────┐
│ App name │ id │ mode │ PID │ status │ restarted │ uptime │      memory │ watching │
├──────────┼────┼──────┼─────┼────────┼───────────┼────────┼─────────────┼──────────┤
│ app      │ 0  │ fork │ 984 │ online │         1 │ 3s     │ 64.141 MB   │ disabled │
└──────────┴────┴──────┴─────┴────────┴───────────┴────────┴─────────────┴──────────┘
 Use `pm2 info <id|name>` to get more details about an app
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

查看启动程序的详细信息：**pm2 describe** id

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[zhoujie@ops-dev uops]$ pm2 desc 0
Describing process with pid 0 - name app
┌───────────────────┬─────────────────────────────────────────┐
│ status            │ online                                  │
│ name              │ app                                     │
│ id                │ 0                                       │
│ path              │ /home/zhoujie/uops/app.js               │
│ args              │                                         │
│ exec cwd          │ /home/zhoujie/uops                      │
│ error log path    │ /home/zhoujie/.pm2/logs/app-error-0.log │
│ out log path      │ /home/zhoujie/.pm2/logs/app-out-0.log   │
│ pid path          │ /home/zhoujie/.pm2/pids/app-0.pid       │
│ mode              │ fork_mode                               │
│ node v8 arguments │                                         │
│ watch & reload    │ ✘                                       │
│ interpreter       │ node                                    │
│ restarts          │ 1                                       │
│ unstable restarts │ 0                                       │
│ uptime            │ 93s                                     │
│ created at        │ 2015-01-07T09:41:25.672Z                │
└───────────────────┴─────────────────────────────────────────┘
[zhoujie@ops-dev uops]$ 
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

通过pm2 list命令来观察所有运行的进程以及它们的状态已经足够好了.但是怎么来追踪它们的资源消耗呢?别担心,用这个命令:**pm2 monit**

**可以得到进程(以及集群)的CPU的使用率和内存占用**(ctrl +c 退出)

![img](F:\Code\github\前端面试\assets\071748590155142.jpg)

**实时集中log处理：pm2 logs**

![img](F:\Code\github\前端面试\assets\071752377962737.jpg)

**强大API： pm2 web**

你想要监控所有被PM2管理的进程,而且同时还想监控运行这些进程的机器的状态，

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
[zhoujie@ops-dev uops]$ pm2 web
Launching web interface on port 9615
[PM2] Process /usr/local/node/lib/node_modules/pm2/lib/HttpInterface.js launched
[PM2] Process launched
┌────────────────────┬────┬──────┬──────┬────────┬───────────┬────────┬─────────────┬──────────┐
│ App name           │ id │ mode │ PID  │ status │ restarted │ uptime │      memory │ watching │
├────────────────────┼────┼──────┼──────┼────────┼───────────┼────────┼─────────────┼──────────┤
│ app                │ 0  │ fork │ 984  │ online │         1 │ 9m     │ 74.762 MB   │ disabled │
│ pm2-http-interface │ 1  │ fork │ 1878 │ online │         0 │ 0s     │ 15.070 MB   │ disabled │
└────────────────────┴────┴──────┴──────┴────────┴───────────┴────────┴─────────────┴──────────┘
 Use `pm2 info <id|name>` to get more details about an app
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

启动程序的时候顺便在浏览器访问：http://localhost:**9615**

擦，我眼睛被亮瞎了，这么炫酷，竟然把部署的服务器的信息和程序的信息都显示出来了：

![img](F:\Code\github\前端面试\assets\071807101408031.png)

这东西对程序运行的监控页面的开发实在是太有帮助了，呵呵~~

监控：pm2 monit
实时集中log处理: pm2 logs
API:pm2 web (端口：9615 ) 

#### 常用命令总结：
```
$ pm2 logs	显示所有进程日志
```

```
$ pm2 stop all	停止所有进程
```

```
$ pm2 restart all	重启所有进程
```

```
$ pm2 reload all	0秒停机重载进程 (用于 NETWORKED 进程)
```

```
$ pm2 stop 0	停止指定的进程
```

```
$ pm2 restart 0	重启指定的进程
```

```
$ pm2 startup	产生 init 脚本 保持进程活着
```

```
$ pm2 web	运行健壮的 computer API endpoint (http://localhost:9615)
```

```
$ pm2 delete 0	杀死指定的进程
```

```
$ pm2 delete all	杀死全部进程
```

运行进程的不同方式：
`$ pm2 start app.js -i max` 根据有效CPU数目启动最大进程数目
`$ pm2 start app.js -i 3` 启动3个进程
`$ pm2 start app.js -x` 用fork模式启动 app.js 而不是使用 cluster
`$ pm2 start app.js -x -- -a 23` 用fork模式启动 app.js 并且传递参数 (-a 23)
`$ pm2 start app.js --name serverone` 启动一个进程并把它命名为 serverone
`$ pm2 stop serverone` 停止 serverone 进程
`$ pm2 start app.json` 启动进程, 在 app.json里设置选项
`$ pm2 start app.js -i max -- -a 23` 在--之后给 app.js 传递参数
`$ pm2 start app.js -i max -e err.log -o out.log` 启动 并 生成一个配置文件

#### 配置pm2启动文件

在项目根目录添加一个processes.json：
内容如下:

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
{
  "apps": [
    {
      "name": "mywork",
      "cwd": "/srv/node-app/current",
      "script": "bin/www",
      "log_date_format": "YYYY-MM-DD HH:mm Z",
      "error_file": "/var/log/node-app/node-app.stderr.log",
      "out_file": "log/node-app.stdout.log",
      "pid_file": "pids/node-geo-api.pid",
      "instances": 6,
      "min_uptime": "200s",
      "max_restarts": 10,
      "max_memory_restart": "1M",
      "cron_restart": "1 0 * * *",
      "watch": false,
      "merge_logs": true,
      "exec_interpreter": "node",
      "exec_mode": "fork",
      "autorestart": false,
      "vizion": false
    }
  ]
}
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

说明:

- apps:json结构，apps是一个数组，每一个数组成员就是对应一个pm2中运行的应用
- name:应用程序名称
- cwd:应用程序所在的目录
- script:应用程序的脚本路径
- log_date_format:
- error_file:自定义应用程序的错误日志文件
- out_file:自定义应用程序日志文件
- pid_file:自定义应用程序的pid文件
- instances:
- min_uptime:最小运行时间，这里设置的是60s即如果应用程序在60s内退出，pm2会认为程序异常退出，此时触发重启max_restarts设置数量
- max_restarts:设置应用程序异常退出重启的次数，默认15次（从0开始计数）
- cron_restart:定时启动，解决重启能解决的问题
- watch:是否启用监控模式，默认是false。如果设置成true，当应用程序变动时，pm2会自动重载。这里也可以设置你要监控的文件。
- merge_logs:
- exec_interpreter:应用程序的脚本类型，这里使用的shell，默认是nodejs
- exec_mode:应用程序启动模式，这里设置的是cluster_mode（集群），默认是fork
- autorestart:启用/禁用应用程序崩溃或退出时自动重启
- vizion:启用/禁用vizion特性(版本控制)

可以通过`pm2 start processes.json`来启动。
也可以把命令写在package.json里。如下:

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
 "scripts": {
    "dev": "NODE_ENV=development nodemon src/server.js & NODE_ENV=development nodemon src/server/action-server.js & tools/redis/socket.js",
    "dev_read_redis": "NODE_ENV=development nodemon src/app.js",
    "start": "NODE_ENV=production nodemon src/app.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

通过`npm run start`来启动。

> 关于pm2远程部署到多台机器，参考：http://pm2.keymetrics.io/docs/usage/deployment

> 官网：http://pm2.keymetrics.io/docs/usage/quick-start/#42-starts

### master挂了的话pm2怎么处理



### 如何和MySQL进行通信

### React声明周期及自己的理解
### 如何配置React-Router
### 路由的动态加载模块
### 服务端渲染SSR
### 介绍路由的history
### 介绍Redux数据流的流程
### Redux如何实现多个组件之间的通信，多个组件使用相同状态如何进行管理
### 多个组件之间如何拆分各自的state，每块小的组件有自己的状态，它们之间还有一些公共的状态需要维护，如何思考这块
### 使用过的Redux中间件
### 如何解决跨域的问题
### 常见Http请求头
### 移动端适配1px的问题
### 介绍flex布局
### 其他css方式设置垂直居中
### 居中为什么要使用transform（为什么不使用marginLeft/Top）
### 使用过webpack里面哪些plugin和loader
### webpack里面的插件是怎么实现的
### dev-server是怎么跑起来
### 项目优化
### 抽取公共文件是怎么配置的
### 项目中如何处理安全问题
### 怎么实现this对象的深拷贝

## 网易

### 介绍redux，主要解决什么问题
### 文件上传如何做断点续传
### 表单可以跨域吗
### promise、async有什么区别
### 搜索请求如何处理（防抖）
### 搜索请求中文如何请求
### 介绍观察者模式
### 介绍中介者模式
### 观察者和订阅###发布的区别，各自用在哪里
### 介绍react优化
### 介绍http2.0
### 通过什么做到并发请求
### http1.1时如何复用tcp连接
### 介绍service worker
### 介绍css3中position:sticky
### redux请求中间件如何处理并发
### 介绍Promise，异常捕获
### 介绍position属性包括CSS3新增
### 浏览器事件流向
### 介绍事件代理以及优缺点
### React组件中怎么做事件代理
### React组件事件代理的原理
### 介绍this各种情况
### 前端怎么控制管理路由
### 使用路由时出现问题如何解决
### React怎么做数据的检查和变化

## 滴滴

### react-router怎么实现路由切换
### react-router里的`<Link>`标签和`<a>`标签有什么区别
### <a>标签默认事件禁掉之后做了什么才实现了跳转
### React层面的性能优化
### 整个前端性能提升大致分几类
### `import { Button } from 'antd'`，打包的时候只打包`button`，分模块加载，是怎么做到的
### 使用`import`时，`webpack`对`node_modules`里的依赖会做什么
### JS异步解决方案的发展历程以及优缺点
### Http报文的请求会有几个部分
### `cookie`放哪里，`cookie`能做的事情和存在的价值
### `cookie`和`token`都存放在`header`里面，为什么只劫持前者
### `cookie`和`session`有哪些方面的区别
### `React`中`Dom`结构发生变化后内部经历了哪些变化
### `React`挂载的时候有3个组件，textComponent、composeComponent、domComponent，区别和关系，Dom结构发生变化时怎么区分data的变化，怎么更新，更新怎么调度，如果更新的时候还有其他任务存在怎么处理
### key主要是解决哪一类的问题，为什么不建议用索引index（重绘）
### Redux中异步的请求怎么处理
### Redux中间件是什么东西，接受几个参数（两端的柯里化函数）
### 柯里化函数两端的参数具体是什么东西
### 中间件是怎么拿到store和action，然后怎么处理
### state是怎么注入到组件的，从reducer到组件经历了什么样的过程
### koa中response.send、response.rounded、response.json发生了什么事，浏览器为什么能识别到它是一个json结构或是html
### koa-bodyparser怎么来解析request
### webpack整个生命周期，loader和plugin有什么区别
### 介绍AST（Abstract Syntax Tree）抽象语法树
### 安卓Activity之间数据是怎么传递的
### 安卓4.0到6.0过程中WebView对js兼容性的变化
### WebView和原生是如何通信
### 跨域怎么解决，有没有使用过Apache等方案

## 今日头条

### 对async、await的理解，内部原理 
### 介绍下Promise，内部实现 
### 清除浮动  
### 定位问题（绝对定位、相对定位等） 
### 从输入URL到页面加载全过程 
### tcp3次握手 
### tcp属于哪一层（1 物理层 ###> 2 数据链路层 ###> 3 网络层(ip)###> 4 传输层(tcp) ###> 5 应用层(http)） 
### redux的设计思想 
### 接入redux的过程 
### 绑定connect的过程 
### connect原理 
### webpack介绍 
### == 和 ===的区别，什么情况下用相等== 
### bind、call、apply的区别 
### 动画的了解 
### 介绍下原型链（解决的是继承问题吗） 
### 对跨域的了解 

## 有赞

### Linux 754 介绍
### 介绍冒泡排序，选择排序，冒泡排序如何优化
### transform动画和直接使用left、top改变位置有什么优缺点
### 如何判断链表是否有环
### 介绍二叉搜索树的特点
### 介绍暂时性死区
### ES6中的map和原生的对象有什么区别
### 观察者和发布###订阅的区别
### react异步渲染的概念,介绍Time Slicing 和 Suspense
### 16.X声明周期的改变
### 16.X中props改变后在哪个生命周期中处理
### 介绍纯函数
### 前端性能优化
### pureComponent和FunctionComponent区别
### 介绍JSX
### 如何做RN在安卓和IOS端的适配
### RN为什么能在原生中绘制成原生组件（bundle.js）
### 介绍虚拟DOM
### 如何设计一个localStorage，保证数据的实效性
### 如何设计Promise.all()
### 介绍高阶组件
### sum(2, 3)实现sum(2)(3)的效果
### react性能优化
### 两个对象如何比较

## 挖财

### JS的原型
### 变量作用域链
### call、apply、bind的区别
### 防抖和节流的区别
### 介绍各种异步方案
### react生命周期
### 介绍Fiber
### 前端性能优化
### 介绍DOM树对比
### react中的key的作用
### 如何设计状态树
### 介绍css，xsrf
### http缓存控制
### 项目中如何应用数据结构
### native提供了什么能力给RN
### 如何做工程上的优化
### `shouldComponentUpdate`是为了解决什么问题
### 如何解决props层级过深的问题
### 前端怎么做单元测试
### webpack生命周期
### webpack打包的整个过程
### 常用的plugins
### pm2怎么做进程管理，进程挂掉怎么处理
### 不用pm2怎么做进程管理

## 沪江

### 介绍下浏览器跨域
### 怎么去解决跨域问题
### jsonp方案需要服务端怎么配合
### Ajax发生跨域要设置什么（前端）
### 加上CORS之后从发起到请求正式成功的过程
### xsrf跨域攻击的安全性问题怎么防范
### 使用Async会注意哪些东西
### Async里面有多个await请求，可以怎么优化（请求是否有依赖）
### Promise和Async处理失败的时候有什么区别
### Redux在状态管理方面解决了React本身不能解决的问题
### Redux有没有做过封装
### react生命周期，常用的生命周期 
### 对应的生命周期做什么事 
### 遇到性能问题一般在哪个生命周期里解决 
### 怎么做性能优化（异步加载组件...）
### 写react有哪些细节可以优化 
### React的事件机制（绑定一个事件到一个组件上）
### 介绍下事件代理，主要解决什么问题
### 前端开发中用到哪些设计模式
### React/Redux中哪些功能用到了哪些设计模式
### JS变量类型分为几种，区别是什么
### JS里垃圾回收机制是什么，常用的是哪种，怎么处理的
### 一般怎么组织CSS（Webpack）

## 饿了么

### 小程序里面开页面最多多少
### React子父组件之间如何传值
### Emit事件怎么发，需要引入什么
### 介绍下React高阶组件，和普通组件有什么区别
### 一个对象数组，每个子对象包含一个id和name，React如何渲染出全部的name
### 在哪个生命周期里写
### 其中有几个name不存在，通过异步接口获取，如何做
### 渲染的时候key给什么值，可以使用index吗，用id好还是index好
### webpack如何配sass，需要配哪些loader
### 配css需要哪些loader
### 如何配置把js、css、html单独打包成一个文件
### div垂直水平居中（flex、绝对定位）
### 两个元素块，一左一右，中间相距10像素
### 上下固定，中间滚动布局如何实现
### [1, 2, 3, 4, 5]变成[1, 2, 3, a, b, 5]
### 取数组的最大值（ES5、ES6）
### apply和call的区别
### ES5和ES6有什么区别
### some、every、find、filter、map、forEach有什么区别
### 上述数组随机取数，每次返回的值都不一样
### 如何找0-5的随机数，95-99呢
### 页面上有1万个button如何绑定事件
### 如何判断是button
### 页面上生成一万个button，并且绑定事件，如何做（JS原生操作DOM）
### 循环绑定时的index是多少，为什么，怎么解决
### 页面上有一个input，还有一个p标签，改变input后p标签就跟着变化，如何处理
### 监听input的哪个事件，在什么时候触发

## 携程

### 对React看法，有没有遇到一些坑
### 对闭包的看法，为什么要用闭包
### 手写数组去重函数
### 手写数组扁平化函数
### 介绍下Promise的用途和性质
### Promise和Callback有什么区别
### React生命周期
### 两道手写算法题

## 喜马拉雅

### ES6新的特性
### 介绍Promise
### Promise有几个状态
### 说一下闭包
### React的生命周期
### componentWillReceiveProps的触发条件是什么
### React16.3对生命周期的改变
### 介绍下React的Filber架构
### 画Filber渲染树
### 介绍React高阶组件
### 父子组件之间如何通信
### Redux怎么实现属性传递，介绍下原理
### React-Router版本号
### 网站SEO怎么处理
### 介绍下HTTP状态码
### 403、301、302是什么
### 缓存相关的HTTP请求头
### 介绍HTTPS
### HTTPS怎么建立安全通道
### 前端性能优化（JS原生和React）
### 用户体验做过什么优化
### 对PWA有什么了解
### 对安全有什么了解
### 介绍下数字签名的原理
### 前后端通信使用什么方案
### RESTful常用的Method
### 介绍下跨域
### Access-Control-Allow-Origin在服务端哪里配置
### csrf跨站攻击怎么解决
### 前端和后端怎么联调

## 兑吧

### localStorage和cookie有什么区别
### CSS选择器有哪些
### 盒子模型，以及标准情况和IE下的区别
### 如何实现高度自适应
### prototype和`——proto——`区别
### `_construct`是什么
### `new`是怎么实现的
### promise的精髓，以及优缺点
### 如何实现H5手机端的适配
### `rem`、`flex`的区别（root em）
### `em`和`px`的区别
### React声明周期
### 如何去除url中的#号
### Redux状态管理器和变量挂载到window中有什么区别
### webpack和gulp的优缺点
### 如何实现异步加载
### 如何实现分模块打包（多入口）
### 前端性能优化（1js css；2 图片；3 缓存预加载； 4 SSR； 5 多域名加载；6 负载均衡）
### 并发请求资源数上限（6个）
### base64为什么能提升性能，缺点
### 介绍webp这个图片文件格式
### 介绍koa2
### Promise如何实现的
### 异步请求，低版本fetch如何低版本适配
### ajax如何处理跨域
### CORS如何设置
### jsonp为什么不支持post方法
### 介绍同源策略
### React使用过的一些组件
### 介绍Immuable
### 介绍下redux整个流程原理
### 介绍原型链
### 如何继承

## 微医

### 介绍JS数据类型，基本数据类型和引用数据类型的区别
### Array是Object类型吗
### 数据类型分别存在哪里
### `var a  = {name: "前端开发"}; var b = a; a = null`那么b输出什么
### `var a = {b: 1}`存放在哪里
### `var a = {b: {c: 1}}`存放在哪里
### 栈和堆的区别
### 垃圾回收时栈和堆的区别
### 数组里面有10万个数据，取第一个元素和第10万个元素的时间相差多少
### 栈和堆具体怎么存储
### 介绍闭包以及闭包为什么没清除
### 闭包的使用场景
### JS怎么实现异步
### 异步整个执行周期
### Promise的三种状态
### Async/Await怎么实现
### Promise和setTimeout执行先后的区别
### JS为什么要区分微任务和宏任务
### Promise构造函数是同步还是异步执行，then呢
### 发布###订阅和观察者模式的区别
### JS执行过程中分为哪些阶段
### 词法作用域和this的区别
### 平常是怎么做继承
### 深拷贝和浅拷贝
### loadsh深拷贝实现原理
### ES6中`let`块作用域是怎么实现的
### React中`setState`后发生了什么
### `setState`为什么默认是异步
### `setState`什么时候是同步的
### 为什么3大框架出现以后就出现很多native（RN）框架（虚拟DOM）
### 虚拟DOM主要做了什么
### 虚拟DOM本身是什么（JS对象）
### 304是什么
### 打包时Hash码是怎么生成的
### 随机值存在一样的情况，如何避免
### 使用webpack构建时有无做一些自定义操作
### webpack做了什么
### a，b两个按钮，点击aba，返回顺序可能是baa，如何保证是aba（Promise.then）
### `node`接口转发有无做什么优化
### `node`起服务如何保证稳定性，平缓降级，重启等
### RN有没有做热加载
### RN遇到的兼容性问题
### RN如何实现一个原生的组件
### RN混原生和原生混RN有什么不同
### 什么是单页项目
### 遇到的复杂业务场景
### Promise.all实现原理

## 寺库

### 介绍Promise的特性，优缺点
### 介绍Redux
### RN的原理，为什么可以同时在安卓和IOS端运行
### RN如何调用原生的一些功能
### 介绍RN的缺点
### 介绍排序算法和快排原理
### 堆和栈的区别
### 介绍闭包
### 闭包的核心是什么
### 网络的五层模型
### HTTP和HTTPS的区别
### HTTPS的加密过程
### 介绍SSL和TLS
### 介绍DNS解析
### JS的继承方法
### 介绍垃圾回收
### cookie的引用为了解决什么问题
### cookie和localStorage的区别
### 如何解决跨域问题
### 前端性能优化

## 宝宝树

### 使用canvas绘图时如何组织成通用组件
### formData和原生的ajax有什么区别
### 介绍下表单提交，和formData有什么关系
### 介绍redux接入流程
### rudux和全局管理有什么区别（数据可控、数据响应）
### RN和原生通信
### 介绍MVP怎么组织
### 介绍异步方案
### promise如何实现then处理
### koa2中间件原理
### 常用的中间件
### 服务端怎么做统一的状态处理
### 如何对相对路径引用进行优化
### node文件查找优先级
### npm2和npm3+有什么区别

## 海康威视

### knex连接数据库响应回调
### 介绍异步方案
### 如何处理异常捕获
### 项目如何管理模块
### 前端性能优化
### JS继承方案
### 如何判断一个变量是不是数组
### 变量a和b，如何交换
### 事件委托
### 多个<li>标签生成的Dom结构是一个类数组
### 类数组和数组的区别
### dom的类数组如何转成数组
### 介绍单页面应用和多页面应用
### redux状态树的管理
### 介绍localstorage的API

## 蘑菇街

### html语义化的理解
### `<b>`和`<strong>`的区别
### 对闭包的理解
### 工程中闭包使用场景
### 介绍this和原型
### 使用原型最大的好处
### react设计思路
### 为什么虚拟DOM比真实DOM性能好
### react常见的通信方式
### redux整体的工作流程
### redux和全局对象之间的区别
### Redux数据回溯设计思路
### 单例、工厂、观察者项目中实际场景
### 项目中树的使用场景以及了解
### 工作收获

## 酷家乐

### react生命周期
### react性能优化
### 添加原生事件不移除为什么会内存泄露
### 还有哪些地方会内存泄露
### setInterval需要注意的点
### 定时器为什么是不精确的
### setTimeout(1)和setTimeout(2)之间的区别
### 介绍宏任务和微任务
### promise里面和then里面执行有什么区别
### 介绍pureComponet
### 介绍Function Component
### React数据流
### props和state的区别
### 介绍react context
### 介绍class和ES5的类以及区别
### 介绍箭头函数和普通函数的区别
### 介绍defineProperty方法，什么时候需要用到
### for..in 和 object.keys的区别
### 介绍闭包，使用场景
### 使用闭包特权函数的使用场景
### get和post有什么区别

## 百分点

### React15/16.x的区别
### 重新渲染render会做些什么
### 哪些方法会触发react重新渲染
### state和props触发更新的生命周期分别有什么区别
### setState是同步还是异步
### 对无状态组件的理解
### 介绍Redux工作流程
### 介绍ES6的功能
### let、const以及var的区别
### 浅拷贝和深拷贝的区别
### 介绍箭头函数的this
### 介绍Promise和then
### 介绍快速排序
### 算法：前K个最大的元素

## 海风教育 

### 对react看法，它的优缺点 

### 使用过程中遇到的问题，如何解决的 

### react的理念是什么（拿函数式编程来做页面渲染）

### JS是什么范式语言(面向对象还是函数式编程)

### koa原理，为什么要用koa(express和koa对比) 

### 使用的koa中间件 

### ES6使用的语法 

### Promise 和 async/await 和 callback的区别 

### Promise有没有解决异步的问题（promise链是真正强大的地方）

### Promise和setTimeout的区别（Event Loop）

### 进程和线程的区别（一个node实例就是一个进程，node是单线程，通过事件循环来实现异步 

  ）

### 介绍下DFS深度优先 

### 介绍下观察者模式 

### 观察者模式里面使用的数据结构(不具备顺序 ，是一个list) 